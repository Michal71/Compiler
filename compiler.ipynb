{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "compiler.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPgRIiUq14b8PcAk/s+0flI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/szubertpiotrek/Compiler/blob/master/compiler.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smKlZCelSJzl",
        "colab_type": "text"
      },
      "source": [
        "# Parser"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5m2vFwzgTtGo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Parser:\n",
        "\n",
        "  ##### Parser header #####\n",
        "  def __init__(self, scanner):\n",
        "    self.next_token = scanner.next_token\n",
        "    self.token = self.next_token()\n",
        "\n",
        "  def take_token(self, token_type):\n",
        "    if self.token.type != token_type:\n",
        "      self.error(\"Unexpected token: %s\" % token_type)\n",
        "    if token_type != 'EOF':\n",
        "      self.token = self.next_token()\n",
        "\n",
        "  def error(self,msg):\n",
        "    raise RuntimeError('Parser error, %s' % msg)\n",
        "\n",
        "  ##### Parser body #####\n",
        "\n",
        "  # Starting symbol\n",
        "  def start(self):\n",
        "    # start -> program EOF\n",
        "    if self.token.type == 'PRINT' or self.token.type == 'ID' or self.token.type == 'EOF' or self.token.type == 'IF':\n",
        "      self.program()\n",
        "      self.take_token('EOF')\n",
        "    else:\n",
        "      self.error(\"Epsilon not allowed\")\n",
        "\n",
        "  def program(self):\n",
        "    # program -> statement program\n",
        "    if self.token.type == 'PRINT' or self.token.type == 'ID' or self.token.type == 'IF':\n",
        "      self.statement()\n",
        "      self.program()\n",
        "    # program -> eps\n",
        "    else:\n",
        "      pass\n",
        "\n",
        "  def statement(self):\n",
        "    # statement -> print_stmt\n",
        "    if self.token.type == 'PRINT':\n",
        "      self.print_stmt()\n",
        "    # statement -> assign_stmt\n",
        "    elif self.token.type == 'ID':\n",
        "      self.assign_stmt()\n",
        "    # statement -> if_stmt\n",
        "    elif self.token.type == 'IF':\n",
        "      self.if_stmt()\n",
        "    else:\n",
        "      self.error(\"Epsilon not allowed\")\n",
        "\n",
        "  # print_stmt -> PRINT value END\n",
        "  def print_stmt(self):\n",
        "    if self.token.type == 'PRINT':\n",
        "      self.take_token('PRINT')\n",
        "      self.value()\n",
        "      self.take_token('END')\n",
        "      print(\"print_stmt OK\")\n",
        "    else:\n",
        "      self.error(\"Epsilon not allowed\")\n",
        "   \n",
        "  # assign_stmt -> ID ASSIGN value END\n",
        "  def assign_stmt(self):\n",
        "    if self.token.type == 'ID':\n",
        "      self.take_token('ID')\n",
        "      self.take_token('ASSIGN')      \n",
        "      self.value()\n",
        "      self.take_token('END')\n",
        "      print(\"assign_stmt OK\")\n",
        "    else:\n",
        "      self.error(\"Epsilon not allowed\")\n",
        "  \n",
        "  def value(self):\n",
        "    # value -> NUMBER\n",
        "    if self.token.type == 'NUMBER':\n",
        "      self.take_token('NUMBER')\n",
        "    # value -> ID\n",
        "    elif self.token.type == 'ID':\n",
        "      self.take_token('ID')\n",
        "    else:\n",
        "      self.error(\"Epsilon not allowed\")\n",
        "\n",
        "  def if_stmt(self):\n",
        "    # if_stmt -> IF ID THEN program ENDIF END\n",
        "    if self.token.type == 'IF':\n",
        "      self.take_token('IF')\n",
        "      self.take_token('ID')\n",
        "      self.take_token('THEN')\n",
        "      self.program()\n",
        "      self.take_token('ENDIF')\n",
        "      self.take_token('END')\n",
        "      print(\"if_stmt OK\")\n",
        "    else:\n",
        "      self.error(\"Epsilon not allowed\")\n",
        "       "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0b2OHNsSRiF",
        "colab_type": "text"
      },
      "source": [
        "# Scanner"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OuS4ga73TnRS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import collections\n",
        "import re\n",
        "\n",
        "Token = collections.namedtuple('Token', ['type', 'value', 'line', 'column'])\n",
        "\n",
        "class Scanner:\n",
        "\n",
        "  def __init__(self, input):\n",
        "    self.tokens = []\n",
        "    self.current_token_number = 0\n",
        "    for token in self.tokenize(input):\n",
        "      self.tokens.append(token)\n",
        " \n",
        "  def tokenize(self, input_string):\n",
        "    keywords = {'\"$id\"', '$schema', 'title', 'title', 'properties', 'description',\n",
        "                'required', 'minimum', 'maximum', 'minLength', 'maxLength', 'enum', 'definitions', '$ref'}\n",
        "    token_specification = [\n",
        "        ('NUMBER',  r'\\d+(\\.\\d*)?'), # Integer or decimal number\n",
        "        ('ASSIGN',  r':'),          # Assignment operator\n",
        "        ('COMMA',     r','),           # Statement terminator\n",
        "        ('ID',      r'\"(.*?)\"'),   # Identifiers   \"(.*?)\"    lub    [$A-Za-z]+\n",
        "        ('NEWLINE', r'\\n'),          # Line endings\n",
        "        ('SKIP',    r'[ \\t]'),       # Skip over spaces and tabs\n",
        "        ('BRACKET_START',    r'\\['),    #cos \n",
        "        ('BRACKET_END',    r'\\]'),    #cos \n",
        "        ('QUOTE',   r'\\\"'),     # First qoute \n",
        "        ('BRACE_START',   r'\\{'),\n",
        "        ('BRACE_END',   r'\\}'),\n",
        "        ('EMPTY',   r'(\\\"\\\")|(\\\"\\s\\\")'),\n",
        "\n",
        "    ]\n",
        "    tok_regex = '|'.join('(?P<%s>%s)' % pair for pair in token_specification)\n",
        "    get_token = re.compile(tok_regex).match\n",
        "    line_number = 1\n",
        "    current_position = line_start = 0\n",
        "    match = get_token(input_string)\n",
        "    while match is not None:\n",
        "        type = match.lastgroup\n",
        "        if type == 'NEWLINE':\n",
        "            line_start = current_position\n",
        "            line_number += 1\n",
        "        elif type != 'SKIP':\n",
        "            value = match.group(type)\n",
        "            if type == 'ID' and value in keywords:\n",
        "                type = value\n",
        "            yield Token(type, value, line_number, match.start()-line_start)\n",
        "        current_position = match.end()\n",
        "        match = get_token(input_string, current_position)\n",
        "    if current_position != len(input_string):\n",
        "        raise RuntimeError('Error: Unexpected character %r on line %d' % \\\n",
        "                              (input_string[current_position], line_number))\n",
        "    yield Token('EOF', '', line_number, current_position-line_start)\n",
        "\n",
        "  def next_token(self):\n",
        "    self.current_token_number += 1\n",
        "    if self.current_token_number-1 < len(self.tokens):\n",
        "      return self.tokens[self.current_token_number-1]\n",
        "    else:\n",
        "      raise RuntimeError('Error: No more tokens')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_YBbfLESWXU",
        "colab_type": "text"
      },
      "source": [
        "# Validator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnKipCyG6qJy",
        "colab_type": "code",
        "outputId": "d6c75eaf-fb21-4183-e19f-40f6e0ef96e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        }
      },
      "source": [
        "# Simple example of parsing\n",
        "# Bartosz Sawicki, 2014-03-13\n",
        "\n",
        "# from scanner import *\n",
        "# from parser import *\n",
        "\n",
        "#input_string = '''\n",
        "#x := 5;\n",
        "#y := x;\n",
        "#PRINT 64;\n",
        "#'''\n",
        "\n",
        "input_string = '''\n",
        "{\n",
        "  \"$id\": \" \",\n",
        "  \"$schema\": \"\",\n",
        "  \"title\": \"Person\",\n",
        "  \"required\": [ \"name\", \"gender\" ]\n",
        "}\n",
        "'''\n",
        "\n",
        "print(input_string)\n",
        "scanner = Scanner(input_string)\n",
        "print(scanner.tokens)\n",
        "\n",
        "parser = Parser(scanner)\n",
        "parser.start()\n",
        "  "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "{\n",
            "  \"$id\": \" \",\n",
            "  \"$schema\": \"\",\n",
            "  \"title\": \"Person\",\n",
            "  \"required\": [ \"name\", \"gender\" ]\n",
            "}\n",
            "\n",
            "[Token(type='BRACE_START', value='{', line=2, column=1), Token(type='\"$id\"', value='\"$id\"', line=3, column=3), Token(type='ASSIGN', value=':', line=3, column=8), Token(type='ID', value='\" \"', line=3, column=10), Token(type='COMMA', value=',', line=3, column=13), Token(type='ID', value='\"$schema\"', line=4, column=3), Token(type='ASSIGN', value=':', line=4, column=12), Token(type='ID', value='\"\"', line=4, column=14), Token(type='COMMA', value=',', line=4, column=16), Token(type='ID', value='\"title\"', line=5, column=3), Token(type='ASSIGN', value=':', line=5, column=10), Token(type='ID', value='\"Person\"', line=5, column=12), Token(type='COMMA', value=',', line=5, column=20), Token(type='ID', value='\"required\"', line=6, column=3), Token(type='ASSIGN', value=':', line=6, column=13), Token(type='BRACKET_START', value='[', line=6, column=15), Token(type='ID', value='\"name\"', line=6, column=17), Token(type='COMMA', value=',', line=6, column=23), Token(type='ID', value='\"gender\"', line=6, column=25), Token(type='BRACKET_END', value=']', line=6, column=34), Token(type='BRACE_END', value='}', line=7, column=1), Token(type='EOF', value='', line=8, column=1)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-2c2c041cb39c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscanner\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-7ebde9aa4188>\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     24\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'EOF'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epsilon not allowed\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mprogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-7ebde9aa4188>\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Parser error, %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0;31m##### Parser body #####\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Parser error, Epsilon not allowed"
          ]
        }
      ]
    }
  ]
}